{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Image registration\n",
    "\n",
    "**Contents:** <br>\n",
    "\n",
    "- [Goal](#goal)<br>\n",
    "- [Deliverables](#deliverables)<br>\n",
    "- [Assessment](#assessment)<br>\n",
    "\n",
    "- [Guided project work](#guided_work)<br>\n",
    "\n",
    "    A. [Getting started](#getting_started)<br>\n",
    "    - [Dataset](#dataset)<br>\n",
    "    - [Selecting corresponding point pairs](#selecting_point_pairs)<br>\n",
    "        \n",
    "  B. [Point-based registration](#point-based_reg)<br>\n",
    "    - [Point-based affine image registration](#affine)<br>\n",
    "    - [Evaluation of point-based affine image registration](#evaluation)<br>\n",
    "        \n",
    "  C. [Intensity-based registration](#intensity-based_reg)<br>\n",
    "    - [Comparing the results of different registration methods](#comparison)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"goal\"></div>\n",
    "\n",
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/read_ico.png\" width=\"42\" height=\"42\"></div> \n",
    "\n",
    "**Clarification:** Following the guided project work below, completing the programming tasks and answering the theory questions, is the minimal solution to this project. If accompanied by a suitable report, this will be graded with a ‘sufficient’ grade.\n",
    "\n",
    "To achieve higher grades, you are expected to go beyond the minimal solution. You should use what you have implemented and the available data to come up with and answer a suitable research question. Write about this in your report.\n",
    "\n",
    "## Goal\n",
    "Develop Python code for point-based and intensity-based (medical) image registration. Use the developed code to perform image registration and evaluate and analyze the results.\n",
    "\n",
    "The dataset you will be using in the first mini-project originates from the [MRBrainS medical image analysis challenge](http://mrbrains13.isi.uu.nl/). It consists of 30 traverse slices of MR brain scans with two different sequences: T1-weighted and T2-FLAIR (5 patients $\\times$ 3 slices per patient $\\times$ 2 modalities). Please see the [Getting started](#getting_started) assignment below for more details on the dataset.\n",
    "\n",
    "<div id=\"deliverables\"></div>\n",
    "\n",
    "## Deliverables\n",
    "Code and a report describing your implementation, results and analysis. There is no hard limit for the length of the report, however, concise and short reports are **strongly** encouraged. Aim to present your most important findings in the main body of the report and (if needed) any additional information in an appendix. The following report structure is suggested for the main body of the report:\n",
    "\n",
    "1. Introduction\n",
    "2. Methods\n",
    "3. Results\n",
    "4. Discussion\n",
    "\n",
    "The introduction and result sections can be very brief in this case (e.g. half a page each). The discussion section should contain the analysis of the results. The report must be submitted as a single PDF file. The code must be submitted as a single archive file (e.g. zip or 7z) that is self-contained and can be used to reproduce the results in the report. \n",
    "\n",
    "Note that there is no single correct solution for the project. You have to demonstrate to the reader that you understand the methods that you have studied and can critically analyze the results of applying the methods. Below, you can find a set of assignments (guided project work) that will help you get started with the project work and, when correctly completed, will present you with a **minimal solution**. Solutions which go beyond these assignments are of course encouraged.\n",
    "\n",
    "<div id=\"assessment\"></div>\n",
    "\n",
    "## Assessment\n",
    "The rubric that will be used for assessment of the project work is given in [this table](https://github.com/tueimage/8dc00-mia/blob/master/rubric.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='guided_work'></div>\n",
    "\n",
    "## Guided project work\n",
    "\n",
    "<div id=\"getting_started\"></div>\n",
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/read_ico.png\" width=\"42\" height=\"42\"></div> \n",
    "\n",
    "### A. Getting started\n",
    "As an introduction, you will get familiar with the dataset that will be used in the first mini-project and the control point selection tool that can be used to annotate corresponding points in pairs of related images. The annotated points can later be used to perform point-based registration and evaluation of the registration error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dataset\"></div>\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The image dataset is located in the [image_data](https://github.com/tueimage/8dc00-mia/tree/master/data/image_data) subfolder of the code for the registration exercises and project. The image filenames have the following format: `{Patient ID}_{Slice ID}_{Sequence}.tif`. For example, the filename `3_2_t1.tif` is the second slice from a T1-weighted scan of the third patient. Every T1 slice comes in two versions: original and transformed with some random transformation that can be identified with the `_d` suffix in the filename. This simulates a registration problem where you have to register two image acquisitions of the same patient (note however that some of the transformations that were used to simulate the second set of images are not realistic for brain imaging, e.g. brain scans typically do not encounter shearing between consecutive acquisitions).\n",
    "\n",
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/question_ico.png\" width=\"42\" height=\"42\"></div> \n",
    "\n",
    "### *Question 1*:\n",
    "\n",
    "With this dataset we can define two image registration problems: T1 to T1 registration (e.g. register `3_2_t1_d.tif` to `3_2_t1.tif`) and T2 to T1 registration (e.g. register `3_2_t2.tif` to `3_2_t1.tif`). Which one of these can be considered inter-modal image registration and which one intra-modal image registration?\n",
    "\n",
    "A: t2  to t1 is intra-modal, because the scans have different aquisition methods. t1 to t1 is inter-modal, because the same method to aquire the images is used, they only differ by an arbitrary transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"selecting_point_pairs\"></div>\n",
    "\n",
    "### Selecting corresponding point pairs\n",
    "\n",
    "A function called `cpselect` is provided to select control points in two different images. This function provides two numpy arrays of cartesian coordinates, one array for each image, of points selected in the two images. The coordinate format is a numpy array with the X and Y on row 0 and 1 respectively, and each column being a point.\n",
    "\n",
    "Calling the function will cause a new interactive window to pop up, where you will see your two images and some instructions.\n",
    "For convenience, the instructions can also be found below:\n",
    "\n",
    "* First select a point in Image 1 and then its corresponding point in Image 2. This pattern should be repeated for as many control points as you need. If you do not follow this pattern, the output arrays will be incorrect.\n",
    "* Left Mouse Button to create a point. \n",
    "* Right Mouse Button/Delete/Backspace to remove the newest point. \n",
    "* Middle Mouse Button/Enter to finish placing points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/todo_ico.png\" width=\"42\" height=\"42\"></div> \n",
    "\n",
    "### *Task 1*:\n",
    "\n",
    "Test the functionality of `cpselect` by running the following code example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[145.12580645 128.51935484 160.45483871]\n",
      " [137.87935484 107.22129032 109.77612903]]\n",
      "Xm:\n",
      "[[140.59677419 127.82258065 157.20322581]\n",
      " [139.15677419 107.22129032 108.49870968]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./code\")\n",
    "import registration_util as util\n",
    "\n",
    "I_path = './image_data/1_1_t1.tif'\n",
    "Im_path = './image_data/1_1_t1_d.tif'\n",
    "\n",
    "X, Xm = util.cpselect(I_path, Im_path)\n",
    "\n",
    "print('X:\\n{}'.format(X))\n",
    "print('Xm:\\n{}'.format(Xm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"point-based_reg\"></div>\n",
    "\n",
    "## B. Point-based registration\n",
    "\n",
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/todo_ico.png\" width=\"42\" height=\"42\"></div> \n",
    "\n",
    "<div id=\"affine\"></div>\n",
    "\n",
    "### Point-based affine image registration\n",
    "\n",
    "From the provided dataset for this project, select one pair of T1 image slices (e.g. `3_2_t1.tif` and `3_2_t1_d.tif`) and use `my_cpselect` to select a set of corresponding points. Then, compute the affine transformation between the pair of images with `ls_affine` and apply it to the moving image using `image_transform`. \n",
    "\n",
    "Repeat the same for a pair of corresponding T1 and T2 slices (e.g. `3_2_t1.tif` and `3_2_t2.tif`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[ 1.25]\n",
      " [-0.25]\n",
      " [64.  ]]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m X1m_h \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mc2h(X1m)\n\u001b[0;32m     26\u001b[0m T1 \u001b[38;5;241m=\u001b[39m reg\u001b[38;5;241m.\u001b[39mls_affine(X1_h, X1m_h)\n\u001b[1;32m---> 28\u001b[0m It1, Xt1 \u001b[38;5;241m=\u001b[39m \u001b[43mreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mImage1d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m X1, X2 \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mcpselect(I_path1, I_path2)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\karli\\OneDrive\\Documenten\\School\\TU Eindhoven\\Programmas\\Github\\8DC00_MIA\\MIA-group-8\\code\\registration.py:113\u001b[0m, in \u001b[0;36mimage_transform\u001b[1;34m(I, Th, output_shape)\u001b[0m\n\u001b[0;32m    109\u001b[0m Xh \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mc2h(X)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m#------------------------------------------------------------------#\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# TODO: Perform inverse coordinates mapping.\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m Th_inv\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m Xt\u001b[38;5;241m=\u001b[39mTh_inv\u001b[38;5;241m.\u001b[39mdot(Xh)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m#------------------------------------------------------------------#\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36minv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\8dc00\\lib\\site-packages\\numpy\\linalg\\linalg.py:545\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    543\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    544\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 545\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\8dc00\\lib\\site-packages\\numpy\\linalg\\linalg.py:88\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.getcwd()\n",
    "# os.chdir(r\"C:\\Users\\karli\\OneDrive\\Documenten\\School\\TU Eindhoven\\Programmas\\Github\\8DC00_MIA\\MIA-group-8\\code\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./code\")\n",
    "import registration_util as util\n",
    "import registration as reg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "I_path1 = './image_data/2_1_t1.tif'\n",
    "Im_path1d = './image_data/2_1_t1_d.tif'\n",
    "I_path2 = './image_data/2_1_t2.tif'\n",
    "\n",
    "Image1 = plt.imread(I_path1)\n",
    "Image1d = plt.imread(Im_path1d)\n",
    "Image2 = plt.imread(I_path2)\n",
    "\n",
    "X1, X1m = util.cpselect(I_path1, Im_path1d)\n",
    "\n",
    "if X1.shape[1] < 2:\n",
    "    raise ValueError('Number of points should be at least 2')\n",
    "X1_h = util.c2h(X1)\n",
    "X1m_h = util.c2h(X1m)\n",
    "T1 = reg.ls_affine(X1_h, X1m_h)\n",
    "\n",
    "It1, Xt1 = reg.image_transform(Image1d, T1)\n",
    "\n",
    "X1, X2 = util.cpselect(I_path1, I_path2)\n",
    "\n",
    "if X1.shape[1] < 2:\n",
    "    raise ValueError('Number of points should be at least 2')\n",
    "X1_h = util.c2h(X1)\n",
    "X2_h = util.c2h(X2)\n",
    "T2 = reg.ls_affine(X1_h, X2_h)\n",
    "\n",
    "It2, Xt2 = reg.image_transform(Image2, T2)\n",
    "\n",
    "print('X1:\\n{}'.format(X1))\n",
    "print('X1m:\\n{}'.format(X1m))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(It1)\n",
    "plt.imshow(It2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"evaluation\"></div>\n",
    "\n",
    "### Evaluation of point-based affine image registration\n",
    "\n",
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/question_ico.png\" width=\"42\" height=\"42\"></div> \n",
    "\n",
    "### *Question 2*:\n",
    "Describe how you would estimate the registration error. (Hint: Should you use the same points that you used for computing the affine transformation to also compute the registration error?) How does the number of corresponding point pairs affect the registration error? Motivate all your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"intensity-based_reg\"></div>\n",
    "\n",
    "## C. Intensity-based registration\n",
    "\n",
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/todo_ico.png\" width=\"42\" height=\"42\"></div> \n",
    "\n",
    "<div id=\"comparison\"></div>\n",
    "\n",
    "### Comparing the results of different registration methods\n",
    "\n",
    "The following Python script (provided as `intensity_based_registration_demo()`) performs rigid intensity-based registration of two images using the normalized-cross correlation as a similarity metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./code\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mregistration_project\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m intensity_based_registration_demo\n\u001b[0;32m      6\u001b[0m intensity_based_registration_demo(corr_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCC\u001b[39m\u001b[38;5;124m\"\u001b[39m, rigid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\karli\\OneDrive\\Documenten\\School\\TU Eindhoven\\Programmas\\Github\\8DC00_MIA\\MIA-group-8\\code\\registration_project.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, clear_output\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcv\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gaussian\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#TODO: terminate als er maar weinig verandering is in de cost function. \u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#TODO: gaande weg hogere mu kiezen...\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#TODO: images genereren met noise\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#TODO: verschil afbeelding\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#TODO: pointbased\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mintensity_based_registration_demo\u001b[39m(I_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./image_data/1_1_t1.tif\u001b[39m\u001b[38;5;124m'\u001b[39m, Im_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./image_data/1_2_t1.tif\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     24\u001b[0m                                       mu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m, num_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m, rigid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, corr_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCC\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# read the fixed and moving images\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# change these in order to read different images\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"./code\")\n",
    "from registration_project import intensity_based_registration_demo\n",
    "\n",
    "intensity_based_registration_demo(corr_metric=\"CC\", rigid=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'add_noise' from 'registration_project' (c:\\Users\\karli\\OneDrive\\Documenten\\School\\TU Eindhoven\\Programmas\\Github\\8DC00_MIA\\MIA-group-8\\code\\registration_project.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./code\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mregistration_project\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_noise\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mregistration_project\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m noise_filtering\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#import registration_project as project\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'add_noise' from 'registration_project' (c:\\Users\\karli\\OneDrive\\Documenten\\School\\TU Eindhoven\\Programmas\\Github\\8DC00_MIA\\MIA-group-8\\code\\registration_project.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./code\")\n",
    "import matplotlib.pyplot as plt\n",
    "from registration_project import add_noise\n",
    "from registration_project import noise_filtering\n",
    "\n",
    "#import registration_project as project\n",
    "\n",
    "\n",
    "im_path = './image_data/3_1_t2.tif'\n",
    "noise_high = add_noise(im_path, True)\n",
    "noise_low = add_noise(im_path, False)\n",
    "\n",
    "filtered_high, filtered_high_ski = noise_filtering(noise_high)\n",
    "filtered_low, filtered_low_ski = noise_filtering(noise_low)\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax1 = fig.add_subplot(3, 2, 1)\n",
    "ax2 = fig.add_subplot(3, 2, 2)\n",
    "ax3 = fig.add_subplot(3, 2, 3)\n",
    "ax4 = fig.add_subplot(3, 2, 4)\n",
    "ax5 = fig.add_subplot(3, 2, 5)\n",
    "ax6 = fig.add_subplot(3, 2, 6)\n",
    "ax1.imshow(filtered_high)\n",
    "ax2.imshow(filtered_low)\n",
    "ax3.imshow(filtered_high_ski)\n",
    "ax4.imshow(filtered_low_ski)\n",
    "ax5.imshow(noise_high)\n",
    "ax6.imshow(noise_low)\n",
    "\n",
    "noise_filtering(noise_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import sys\n",
    "sys.path.append(\"./code\")\n",
    "\n",
    "img = cv.imread('./image_data/1_1_t1.tif')\n",
    "\n",
    "cv.imshow(\"Display window\", img)\n",
    "k = cv.waitKey(0) # Wait for a keystroke in the window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/todo_ico.png\" width=\"42\" height=\"42\"></div> \n",
    "\n",
    "### *Task 2*:\n",
    "\n",
    "By changing the similarity function and the initial parameter vector, you can also use this script to perform affine registration and use mutual information as a similarity measure. Do not forget to also change the transformation for the visualization of the results.\n",
    "\n",
    "Using the provided dataset and the functions that you have implemented in the exercises, perform the following series of experiments:\n",
    "\n",
    "1. Rigid intensity-based registration of two T1 slices (e.g. `1_1_t1.tif` and `1_1_t1_d.tif`) using normalized cross-correlation as a similarity measure.\n",
    "2. Affine intensity-based registration of two T1 slices (e.g. `1_1_t1.tif` and `1_1_t1_d.tif`) using normalized cross-correlation as a similarity measure.\n",
    "3. Affine intensity-based registration of a T1 and a T2 slice (e.g. `1_1_t1.tif` and `1_1_t2.tif`) using normalized cross-correlation as a similarity measure.\n",
    "4. Affine intensity-based registration of two T1 slices (e.g. `1_1_t1.tif` and `1_1_t1_d.tif`) using mutual information as a similarity measure.\n",
    "5. Affine intensity-based registration of a T1 slice and a T2 slice (e.g. `1_1_t1.tif` and `1_1_t2.tif`) using mutual information as a similarity measure.\n",
    "\n",
    "Describe, analyze and compare the results from each experiment. If a method fails, describe why you think it fails. Note that you will most likely have to try different values for the learning rate in each experiment in order to find the one that works best. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "7cf3cfb4d2a53586223bf4603cd7f9e645cf44a77dbcec96182c9a81e54296ad"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
